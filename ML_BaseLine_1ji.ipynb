{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习模型进行multi-lable分类（一级标签），步骤：\n",
    "\n",
    "1. 读取数据，并将数据切分至train data、cross validation data、test data\n",
    "2. 文本向量化：onehot与tfidf\n",
    "3. 模型训练：多标签模型knn、svm\n",
    "4. 交叉验证cross validation，选择优参数\n",
    "5. 用test data 输出不同模型的准确度，给出展示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 读取数据，并将数据切分至train data、cross validation data、test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id  \\\n",
      "0  2eff3829-23bd-401f-a283-5a73d1695118   \n",
      "1  7282cc20-3d24-41ab-a599-5e08f0d0940b   \n",
      "2  a8c3c018-e006-42d3-8cd1-0f531e4a8846   \n",
      "3  4b284b4f-e58c-4c25-b47a-23003efc157f   \n",
      "4  43421dd5-6538-498a-8fde-4310f7c0c537   \n",
      "\n",
      "                                            pure_fea 1ji_lable  \n",
      "0  数列 ENUM_SET SEQ_ELEMENT EQUAL NUM VARa VARn NU...         1  \n",
      "1  数列 ENUM_SET 是以 NUM 首项 NUM 公差 等差数列 数列 ENUM_SET ...       1,2  \n",
      "2  ENUM_SET 正项 等比数列 SEQ_SUM EQUAL LOG SEQ_ELEMENT...         1  \n",
      "3  数据 NUM NUM NUM NUM NUM NUM 标准差 TARGET NUM NUM ...       2,4  \n",
      "4  解 VARx 不等式 FRAC INEQUAL NUM nan 解 原 不等式 VARx N...         0  \n",
      "                                     id  \\\n",
      "0  19ceb8ad-e997-47c3-a77a-f28468f6631d   \n",
      "1  201c1bda-f139-4c3d-80cc-13e28d519985   \n",
      "2  d7b2f640-f5c2-4c7a-a684-48e2f44ddff0   \n",
      "3  b3f6c713-1851-45e9-b6ae-960b47e381fe   \n",
      "4  07ec1e1f-ba0f-423b-acc0-089d9eaa9440   \n",
      "\n",
      "                                            pure_fea   1ji_lable  \n",
      "0  集合 VARA ENUM_SET VARA INTERSECT VARB EQUAL TAR...       ['2']  \n",
      "1  复数 NUM MINUS VARi VARa PLUS VARi 复平面 内 对应 点在 第...       ['2']  \n",
      "2  执行 如图所示 程序框图 输出 VARS 值 TARGET IMG NUM nan 解 VA...  ['1', '2']  \n",
      "3  VARx VARy PIECEWISE VARx NUM VARy 最大值 TARGET N...  ['2', '3']  \n",
      "4  函数 FUN_VALUE_VAR EQUAL NUM_INDEX MINUS NUM_IND...  ['0', '1']  \n"
     ]
    }
   ],
   "source": [
    "# 首先读取文本\n",
    "import pandas as pd\n",
    "MaoTi_all = pd.read_csv('Data\\MaoTi_all_1ji_lable.0205') # 读取锚题\n",
    "ZhenTi_all = pd.read_csv('Data\\ZhenTi_all_1ji_lable.0205') # 读取真题，获取x\n",
    "print(MaoTi_all.head())\n",
    "print(ZhenTi_all.head())\n",
    "\n",
    "# 用于获取 lable\n",
    "MaoTi_source = pd.read_excel('Data\\MaoTi_source.xlsx')\n",
    "ZhenTi_source = pd.read_excel('Data\\\\2017年高考数学试卷标注统计.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n",
      "[['B'], ['B', 'C'], ['B'], ['C', 'E'], ['A']]\n"
     ]
    }
   ],
   "source": [
    "# 1. 数据集全部由锚题构成（因为锚题覆盖广 质量高700个）\n",
    "train_x = MaoTi_all['pure_fea']\n",
    "\n",
    "# 获取一级标签\n",
    "train_y=[]\n",
    "for i in range(0,len(MaoTi_source)): # 注意：这个切片参数，锚题从0行开始遍历，真题从1行开始遍历\n",
    "    onehot_y = []\n",
    "    if MaoTi_source.iloc[i,1] == 1 or MaoTi_source.iloc[i,2] == 1 or MaoTi_source.iloc[i,3] == 1: # A\n",
    "        onehot_y.append('A')\n",
    "    if MaoTi_source.iloc[i,4] == 1 or MaoTi_source.iloc[i,5] == 1 or MaoTi_source.iloc[i,6] == 1 or MaoTi_source.iloc[i,7] == 1: # B\n",
    "        onehot_y.append('B')\n",
    "    if MaoTi_source.iloc[i,8] == 1 or MaoTi_source.iloc[i,9] == 1 or MaoTi_source.iloc[i,10] == 1: # C\n",
    "        onehot_y.append('C')\n",
    "    if MaoTi_source.iloc[i,11] == 1 or MaoTi_source.iloc[i,12] == 1 or MaoTi_source.iloc[i,13] == 1 or MaoTi_source.iloc[i,14] == 1: # D\n",
    "        onehot_y.append('D')\n",
    "    if MaoTi_source.iloc[i,15] == 1 or MaoTi_source.iloc[i,16] == 1 or MaoTi_source.iloc[i,17] == 1: # E\n",
    "        onehot_y.append('E')\n",
    "    if MaoTi_source.iloc[i,18] == 1 or MaoTi_source.iloc[i,19] == 1 or MaoTi_source.iloc[i,20] == 1 or MaoTi_source.iloc[i,21] == 1: # F\n",
    "        onehot_y.append('F')\n",
    "    \n",
    "    train_y.append(onehot_y)\n",
    "print(len(train_y)) # [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0\n",
    "print(train_y[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n",
      "[['C'], ['C'], ['B', 'C'], ['C', 'D'], ['A', 'B']]\n"
     ]
    }
   ],
   "source": [
    "# 2. 真题集（各329个）\n",
    "ZhenTi_x = ZhenTi_all['pure_fea']\n",
    "ZhenTi_y = []\n",
    "\n",
    "for i in range(1,len(ZhenTi_source)): # 注意：这个切片参数，锚题从0行开始遍历，真题从1行开始遍历\n",
    "    onehot_y = []\n",
    "    if ZhenTi_source.iloc[i,1] == 1 or ZhenTi_source.iloc[i,2] == 1 or ZhenTi_source.iloc[i,3] == 1: # A\n",
    "        onehot_y.append('A')\n",
    "    if ZhenTi_source.iloc[i,4] == 1 or ZhenTi_source.iloc[i,5] == 1 or ZhenTi_source.iloc[i,6] == 1 or ZhenTi_source.iloc[i,7] == 1: # B\n",
    "        onehot_y.append('B')\n",
    "    if ZhenTi_source.iloc[i,8] == 1 or ZhenTi_source.iloc[i,9] == 1 or ZhenTi_source.iloc[i,10] == 1: # C\n",
    "        onehot_y.append('C')\n",
    "    if ZhenTi_source.iloc[i,11] == 1 or ZhenTi_source.iloc[i,12] == 1 or ZhenTi_source.iloc[i,13] == 1 or ZhenTi_source.iloc[i,14] == 1: # D\n",
    "        onehot_y.append('D')\n",
    "    if ZhenTi_source.iloc[i,15] == 1 or ZhenTi_source.iloc[i,16] == 1 or ZhenTi_source.iloc[i,17] == 1: # E\n",
    "        onehot_y.append('E')\n",
    "    if ZhenTi_source.iloc[i,18] == 1 or ZhenTi_source.iloc[i,19] == 1 or ZhenTi_source.iloc[i,20] == 1 or ZhenTi_source.iloc[i,21] == 1: # F\n",
    "        onehot_y.append('F')\n",
    "    \n",
    "    ZhenTi_y.append(onehot_y)\n",
    "print(len(ZhenTi_y)) # [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0\n",
    "print(ZhenTi_y[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    数列 ENUM_SET SEQ_ELEMENT EQUAL NUM VARa VARn NU...\n",
      "1    数列 ENUM_SET 是以 NUM 首项 NUM 公差 等差数列 数列 ENUM_SET ...\n",
      "2    ENUM_SET 正项 等比数列 SEQ_SUM EQUAL LOG SEQ_ELEMENT...\n",
      "3    数据 NUM NUM NUM NUM NUM NUM 标准差 TARGET NUM NUM ...\n",
      "4    解 VARx 不等式 FRAC INEQUAL NUM nan 解 原 不等式 VARx N...\n",
      "Name: pure_fea, dtype: object [['B'], ['B', 'C'], ['B'], ['C', 'E'], ['A']] 700\n",
      "------------------------------------------------------------------------------------\n",
      "320    TRIANGLE LINE EQUAL LINE EQUAL NUM LINE EQUAL ...\n",
      "23     VARx VARy PIECEWISE VARx NUM VARy 最大值 TARGET N...\n",
      "109    函数 FUN_VALUE_VAR EQUAL LOG VARx PLUS VAR_QUA P...\n",
      "98     正方体 4PRISM VARE 棱 ARC 中点 TARGET LINE PERP LINE...\n",
      "28     平面 直角 坐标系 COOTDINATE_SYSTEM 角 ALPHA 角 BETA 均以 ...\n",
      "Name: pure_fea, dtype: object [['C', 'D'], ['C', 'D'], ['A', 'B', 'C'], ['B', 'C', 'D'], ['A', 'B']] 164\n",
      "------------------------------------------------------------------------------------\n",
      "160    设有 下面 四个 命题 SEQ_ELEMENT 复数 VARz FRAC BELONG VA...\n",
      "75     椭圆 VARC OVAL VARa INEQUAL VARb INEQUAL NUM 左 右...\n",
      "225    集合 VARM ENUM_SET ABS VARN ENUM_SET VARM INTERS...\n",
      "253    定义 INTEVAL PINF 函数 POINT_SLOPE_EQUA FUN_VALUE_...\n",
      "306    椭圆 OVAL VARa INEQUAL VARb INEQUAL NUM 左 焦点 POI...\n",
      "Name: pure_fea, dtype: object [['B', 'C'], ['B', 'C'], ['C'], ['A', 'C'], ['B', 'C', 'D']] 165\n"
     ]
    }
   ],
   "source": [
    "# 划分数据集：把真题分割为 交叉验证集 与测试集（各164个）\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "crossVali_x, test_x, crossVali_y, test_y = train_test_split(ZhenTi_x, ZhenTi_y, test_size=0.5)\n",
    "\n",
    "print(train_x[:5],train_y[:5],len(train_y))\n",
    "print('------------------------------------------------------------------------------------')\n",
    "print(crossVali_x[:5],crossVali_y[:5],len(crossVali_y))\n",
    "print('------------------------------------------------------------------------------------')\n",
    "print(test_x[:5],test_y[:5],len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'B' 'C' 'D' 'E' 'F']\n",
      "[[0 1 0 0 0 0]\n",
      " [0 1 1 0 0 0]\n",
      " [0 1 0 0 0 0]] [[0 0 1 1 0 0]\n",
      " [0 0 1 1 0 0]\n",
      " [1 1 1 0 0 0]] [[0 1 1 0 0 0]\n",
      " [0 1 1 0 0 0]\n",
      " [0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 把标签 01化！\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes = ['A','B','C','D','E','F'])\n",
    "train_y_lable = mlb.fit_transform(train_y)\n",
    "crossVali_y_lable = mlb.fit_transform(crossVali_y)\n",
    "test_y_lable = mlb.fit_transform(test_y)\n",
    "print(mlb.classes_)\n",
    "\n",
    "print(train_y_lable[:3],crossVali_y_lable[:3],test_y_lable[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 文本向量化：onehot与tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       数列 ENUM_SET SEQ_ELEMENT EQUAL NUM VARa VARn NU...\n",
      "1       数列 ENUM_SET 是以 NUM 首项 NUM 公差 等差数列 数列 ENUM_SET ...\n",
      "2       ENUM_SET 正项 等比数列 SEQ_SUM EQUAL LOG SEQ_ELEMENT...\n",
      "3       数据 NUM NUM NUM NUM NUM NUM 标准差 TARGET NUM NUM ...\n",
      "4       解 VARx 不等式 FRAC INEQUAL NUM nan 解 原 不等式 VARx N...\n",
      "5       函数 FUN_VALUE_VAR EQUAL ABS PLUS ABS FUN_VALUE_...\n",
      "6       等比数列 ENUM_SET SEQ_ELEMENT PLUS SEQ_ELEMENT PLU...\n",
      "7       不等式 组 PIECEWISE 平面 区域内 整点 横坐标 和 纵坐标 都是 整数 点 个数...\n",
      "8       IMG 四 棱锥 5HEDRON VARE ARC 中点 VARF ARC 中点 LINE ...\n",
      "9       实数 VARx VARy PIECEWISE NUM VARx NUM VARy 取值 范围...\n",
      "10      四个 几何体 三视图 这四个 几何体 依次 分 别是 TARGET IMG 三 棱台 三棱柱...\n",
      "11      IMG 如图所示 三棱锥 4HEDRON LINE PERP 平面 PLANE LINE P...\n",
      "12      IMG 4PRISM 正方体 下面 结论 正确 TARGET LINE PARAL 平面 P...\n",
      "13      不等式 FRAC_SYMBOL VAR_POW NUM NUM NUM VARx MINUS...\n",
      "14      直线 LINE_EQUA 直线 LINE_EQUA 平行 这两条 平行线 之间 距离 nan...\n",
      "15      ENUM_SET 等比数列 SEQ_ELEMENT PLUS SEQ_ELEMENT EQU...\n",
      "16      点 POINT_3DIM COOTDINATE_SYSTEM 平面 对称点 坐标 TARGE...\n",
      "17      某人 楼房 一幢 室内 面积 共计 NUM VAR_QUA 拟 分 割成 两类 房间 作为 ...\n",
      "18      FRAC PI INEQUAL THETA INEQUAL FRAC PI 下列 选项 正确...\n",
      "19      执行 程序框图 输出 VARS EQUAL TARGET IMG nan NUM 解 程序框...\n",
      "20      数列 NUM NUM NUM NUM CDOTS 这个 数列 特点是 第二 项 起 每一项 ...\n",
      "21      函数 FUN_VALUE_VAR 定义 VARR 减函数 函数 VARy EQUAL FUN...\n",
      "22      VARx 进位制 十进位制 数 NUM 记为 NUM VARx TARGET NUM NUM...\n",
      "23      方程 VARx NUM EQUAL SQRT_SYMBOL NUM MINUS POW 曲线...\n",
      "24      IMG 四 棱锥 5HEDRON 底面 PLANE 平行四边形 LINE EQUAL LIN...\n",
      "25      集合 VARM ENUM_SET VARN ENUM_SET 使 VARM INTERSEC...\n",
      "26      数列 ENUM_SET 前 VARn 项 和 SEQ_SUM EQUAL VAR_QUA P...\n",
      "27      函数 FUN_VALUE_VAR EQUAL FRAC_SQRT SQRT 定义域 VARM...\n",
      "28      航模 小组 进行 飞机 模型 实验 飞机 模型 第一 分钟 间里 升了 NUM 米 高度 通...\n",
      "29      不等式 VAR_QUA NUM VARx NUM INEQUAL NUM 解 x frac ...\n",
      "                              ...                        \n",
      "999     VARa VARb BELONG VARR VARa VARb INEQUAL NUM FR...\n",
      "1000    TRIANGLE VARA EQUAL DEGREE LINE EQUAL NUM LINE...\n",
      "1001    TRIANGLE 内角 VARA VARB VARC 边 分别为 VARa VARb VAR...\n",
      "1002    电视台 播放 甲 乙 两套 连续剧 每次 播放 连续剧 需要 播放 广告 每次 播放 甲 乙...\n",
      "1003    IMG 四 棱锥 5HEDRON LINE PERP 平面 PLANE LINE PARAL...\n",
      "1004    ENUM_SET 等差数列 前 VARn 项 和 SEQ_SUM VARn BELONG I...\n",
      "1005    VARa VARb BELONG VARR ABS INEQUAL NUM 函数 FUN_V...\n",
      "1006    椭圆 OVAL VARa INEQUAL VARb INEQUAL NUM 左 焦点 POI...\n",
      "1007    集合 VARP EQUAL VARx NUM INTEVAL INTEVAL INTEVAL...\n",
      "1008    椭圆 OVAL 离心率 TARGET nan nan 解 椭圆 OVAL 可得 VARa E...\n",
      "1009    IMG 几何体 三视图 如图所示 单位 VARc VARm 几何体 体积 单位 VAR_QU...\n",
      "1010    VARx VARy 约束条件 PIECEWISE VARz EQUAL VARx NUM V...\n",
      "1011    函数 FUN_VALUE_VAR EQUAL VAR_QUA PLUS VARa VARx ...\n",
      "1012    等差数列 ENUM_SET 公差 VARd 前 VARn 项 和 SEQ_SUM VARd ...\n",
      "1013    IMG 函数 POINT_SLOPE_EQUA FUN_VALUE_VAR 导函数 VARy...\n",
      "1014    随机变量 VARξ VARi VARP VARξ VARi EQUAL NUM EQUAL ...\n",
      "1015    IMG 正 四面体 d-abc 所有 棱 长 均 相等 三棱锥 VARP VARQ VARR...\n",
      "1016    IMG 平面 四边形 PLANE LINE PERP LINE LINE EQUAL LIN...\n",
      "1017    我国 古代 数学家 刘徽 创立 割 圆 术 估算 圆周率 PI 理论上 能把 PI 值计 算...\n",
      "1018    VARa VARb BELONG VARR POW 3+4i i 虚数 单位 VAR_QUA...\n",
      "1019    多项式 POW POW EQUAL VAR_POW PLUS SEQ_ELEMENT VAR...\n",
      "1020    TRIANGLE LINE EQUAL LINE EQUAL NUM LINE EQUAL ...\n",
      "1021    向量 VECTOR VECTOR MOLD ABS VECTOR EQUAL NUM MOL...\n",
      "1022    NUM 男 NUM 女 共 NUM 名 学生 选出 队长 NUM 人 副队长 NUM 人 普...\n",
      "1023    VARa BELONG VARR 函数 FUN_VALUE_VAR EQUAL ABS FR...\n",
      "1024    函数 FUN_VALUE_VAR EQUAL SIN_QUA SIN VARx MINUS ...\n",
      "1025    IMG 四 棱锥 5HEDRON TRIANGLE 是以 ARC 斜边 等腰 直角三角形 L...\n",
      "1026    函数 FUN_VALUE_VAR EQUAL VARx MINUS SQRT EXP_IND...\n",
      "1027    IMG 抛物线 PARABOLA 点 POINT_2DIM INTEVAL FRAC FRA...\n",
      "1028    数列 ENUM_SET VARx ENUM_SET EQUAL NUM VARx VARn ...\n",
      "Name: pure_fea, Length: 1029, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 构建向量训练集（所有的特征文本x之和）\n",
    "\n",
    "data_samples = MaoTi_all['pure_fea'].append(ZhenTi_all['pure_fea'], ignore_index=True)\n",
    "print(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 61)\t1\n",
      "  (0, 66)\t2\n",
      "  (0, 68)\t6\n",
      "  (0, 74)\t1\n",
      "  (0, 93)\t1\n",
      "  (0, 94)\t19\n",
      "  (0, 95)\t18\n",
      "  (0, 101)\t6\n",
      "  (0, 102)\t1\n",
      "  (0, 103)\t1\n",
      "  (0, 105)\t1\n",
      "  (0, 114)\t2\n",
      "  (0, 116)\t1\n",
      "  (0, 119)\t1\n",
      "  (0, 123)\t3\n",
      "  (0, 127)\t1\n",
      "  (0, 134)\t8\n",
      "  (0, 137)\t1\n",
      "  (0, 141)\t38\n",
      "  (0, 142)\t11\n",
      "  (0, 143)\t6\n",
      "  (0, 147)\t1\n",
      "  (0, 160)\t10\n",
      "  (0, 163)\t2\n",
      "  (0, 165)\t2\n",
      "  :\t:\n",
      "  (163, 160)\t7\n",
      "  (163, 180)\t6\n",
      "  (163, 201)\t1\n",
      "  (163, 209)\t2\n",
      "  (163, 218)\t3\n",
      "  (163, 225)\t1\n",
      "  (163, 227)\t1\n",
      "  (163, 231)\t5\n",
      "  (163, 232)\t1\n",
      "  (163, 233)\t1\n",
      "  (163, 340)\t1\n",
      "  (163, 529)\t1\n",
      "  (163, 859)\t1\n",
      "  (163, 926)\t1\n",
      "  (163, 975)\t1\n",
      "  (163, 1337)\t1\n",
      "  (163, 1355)\t2\n",
      "  (163, 1427)\t1\n",
      "  (163, 1492)\t1\n",
      "  (163, 1555)\t1\n",
      "  (163, 1941)\t1\n",
      "  (163, 2316)\t1\n",
      "  (163, 2567)\t3\n",
      "  (163, 3257)\t1\n",
      "  (163, 3530)\t1\n"
     ]
    }
   ],
   "source": [
    "# 构建 词频tf 向量\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tf_vectorizer = CountVectorizer()\n",
    "tf = tf_vectorizer.fit_transform(data_samples) # 训练文本词典\n",
    "\n",
    "train_x_tf_vct = tf_vectorizer.transform(train_x)\n",
    "crossVali_x_tf_vct = tf_vectorizer.transform(crossVali_x)\n",
    "test_x_tf_vct = tf_vectorizer.transform(test_x)\n",
    "\n",
    "print(crossVali_x_tf_vct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3640)\t0.04369266113202153\n",
      "  (0, 3479)\t0.05831451861070061\n",
      "  (0, 3384)\t0.037312510458715566\n",
      "  (0, 3019)\t0.05540263789462346\n",
      "  (0, 2972)\t0.023888027768830315\n",
      "  (0, 2968)\t0.06230599994840418\n",
      "  (0, 2856)\t0.048881517258518935\n",
      "  (0, 2563)\t0.09683129768628385\n",
      "  (0, 2333)\t0.054782209915695455\n",
      "  (0, 1941)\t0.028063920961139504\n",
      "  (0, 1840)\t0.06868615062171016\n",
      "  (0, 1728)\t0.02170665808665406\n",
      "  (0, 1510)\t0.022325401494372208\n",
      "  (0, 1141)\t0.039303073441450107\n",
      "  (0, 1096)\t0.06230599994840418\n",
      "  (0, 883)\t0.042658113490569444\n",
      "  (0, 859)\t0.02756130642663402\n",
      "  (0, 597)\t0.05165955491542094\n",
      "  (0, 590)\t0.059183344948129664\n",
      "  (0, 531)\t0.08571456970110505\n",
      "  (0, 342)\t0.04347771282948053\n",
      "  (0, 292)\t0.04725841988298674\n",
      "  (0, 222)\t0.04459772968865918\n",
      "  (0, 220)\t0.030733188425426508\n",
      "  (0, 213)\t0.07691229963623665\n",
      "  :\t:\n",
      "  (163, 751)\t0.04507689421621769\n",
      "  (163, 597)\t0.049586922352193086\n",
      "  (163, 529)\t0.026502771448519504\n",
      "  (163, 342)\t0.12520003164890794\n",
      "  (163, 340)\t0.03653433502351063\n",
      "  (163, 211)\t0.2503595117304211\n",
      "  (163, 210)\t0.45065628760352755\n",
      "  (163, 209)\t0.20786635458220298\n",
      "  (163, 208)\t0.16924480921920512\n",
      "  (163, 203)\t0.05097819125715243\n",
      "  (163, 202)\t0.0723374343259248\n",
      "  (163, 201)\t0.05300554289703901\n",
      "  (163, 184)\t0.24580798181656907\n",
      "  (163, 180)\t0.35100687192759294\n",
      "  (163, 167)\t0.06529181020454967\n",
      "  (163, 160)\t0.20307603197077945\n",
      "  (163, 156)\t0.02931240690668973\n",
      "  (163, 141)\t0.29365428015711564\n",
      "  (163, 137)\t0.01624211517293201\n",
      "  (163, 134)\t0.0364896751871507\n",
      "  (163, 101)\t0.16206796359857883\n",
      "  (163, 95)\t0.25485793597078893\n",
      "  (163, 79)\t0.14876076705657926\n",
      "  (163, 75)\t0.3184146795075565\n",
      "  (163, 67)\t0.03159093841282259\n"
     ]
    }
   ],
   "source": [
    "# 构建 tfidf 向量\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples) # 训练文本词典\n",
    "\n",
    "train_x_tfidf_vct = tfidf_vectorizer.transform(train_x)\n",
    "crossVali_x_tfidf_vct = tfidf_vectorizer.transform(crossVali_x)\n",
    "test_x_tfidf_vct = tfidf_vectorizer.transform(test_x)\n",
    "\n",
    "print(crossVali_x_tfidf_vct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "函数： [-1.7640394e+00  4.2826529e+00 -2.0158744e+00  4.3612938e+00\n",
      " -1.4179142e-01 -3.9970086e+00  5.0811305e+00  3.0308080e+00\n",
      "  1.7861323e+00  1.8621773e+00  2.9964063e+00 -1.0679901e-02\n",
      "  7.3306009e-02 -3.9404211e+00 -1.1000518e+00 -4.8098516e-01\n",
      " -1.1832634e-02 -2.4092910e+00  6.8852174e-01 -1.8851600e+00\n",
      "  1.3572416e+00 -2.2222576e-01  3.3028390e+00  2.7103631e+00\n",
      " -6.2310886e-01 -2.0284886e+00  1.2591255e+00 -9.4247746e-01\n",
      " -2.0697088e+00 -2.4347372e+00  3.5791700e+00  4.8177678e-02\n",
      "  4.4821227e-01 -7.5631404e-01  2.4531932e+00 -1.6476452e+00\n",
      " -2.1549761e+00 -2.4570816e+00  1.3004451e-01  3.8428608e-01\n",
      " -2.3210716e-02  1.8017774e+00 -2.4330514e-03 -1.0911762e+00\n",
      "  8.7242931e-01  2.4945409e+00 -1.9489281e+00  2.6281452e-01\n",
      " -7.4507135e-01 -2.4338728e-01  4.3852153e+00 -3.2129185e+00\n",
      " -5.4083955e-01 -6.1659431e-01  3.9333200e+00  1.9449939e+00\n",
      "  3.6641340e+00 -4.0597546e-01  1.2550095e+00 -1.4503902e+00\n",
      "  1.0216436e+00 -5.3371626e-01 -3.4621243e+00 -2.5685060e-01\n",
      "  2.7214766e+00  1.6382653e+00 -5.4667957e-02 -2.0727286e+00\n",
      " -8.5311824e-01 -1.5364306e-01 -4.7214201e-01  1.7373956e+00\n",
      " -5.0215197e+00  1.1688772e+00 -2.7137048e+00 -1.9968358e+00\n",
      "  4.3599558e-01 -1.4368808e+00 -4.1525869e+00  7.9226285e-01\n",
      " -9.1337234e-01 -2.6372294e+00 -7.3066324e-02 -9.4267696e-01\n",
      " -1.8246661e+00  2.6207530e+00 -5.4050794e+00  5.4988575e-01\n",
      "  9.1304189e-01 -1.3998452e+00 -9.8648632e-01  1.5829214e+00\n",
      " -2.9249377e+00 -1.2913209e+00  1.7572925e+00 -6.3294506e-01\n",
      "  1.5874481e+00 -2.1095469e+00 -4.8568540e+00  1.0002484e+00]\n",
      "NUM： [-0.15857676 -0.4126832   0.01858359  1.4774885   0.5911816   1.0510956\n",
      " -1.2216636  -1.5310576  -0.4318445   0.35820466 -0.57437265  2.5961683\n",
      "  2.309325    1.281514   -2.539866    2.0523615   1.876867    1.0028803\n",
      "  0.3983617  -1.5623194  -1.0962188   0.25554535  0.57936853  2.1036828\n",
      "  1.4577764  -0.5690211  -0.74648297  0.8188904  -1.4349049  -1.0580752\n",
      "  2.4500837  -0.39867446  1.436412    3.3180397  -0.8277362  -0.47443098\n",
      " -1.1905882   0.26280278 -0.7300947  -1.4222772  -0.96332747  1.7959677\n",
      " -1.9773285   0.5487317   0.50891787  1.1230893  -1.9441658  -2.1283042\n",
      "  0.64555174  3.3562202   3.0992436   0.10149325  1.4621134  -1.8267941\n",
      "  0.8279329  -1.3503519   0.16679774 -0.9800626  -0.61217725 -1.83011\n",
      " -1.513482    2.670365    0.914018    0.94650424 -0.6138636  -0.7148745\n",
      "  1.4901495   0.895492    0.34816414 -1.9191651  -0.25864437 -1.9536299\n",
      " -3.103853    0.48737368 -3.6917248  -0.8140876  -2.2218752  -1.177453\n",
      "  0.49013448 -1.8928688   1.7540493   0.7705013  -0.41752592  0.14845963\n",
      " -0.29846337 -0.1484247  -2.0424435   2.045911   -2.1710768  -1.8424722\n",
      "  2.0233474   0.29835632 -0.40471056  2.3545017   1.3960414   0.7794063\n",
      " -0.43939778 -0.9696704   0.9610323   3.937499  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programming\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "C:\\Programming\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "# 使用word2vec词向量特征\n",
    "# 首先 读取模型（模型在95服务器上训练）\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "# 分词\n",
    "def getSentences(path):\n",
    "    '''\n",
    "    获得用于词向量训练的句子\n",
    "    :param path: 文件存储的路径\n",
    "    :return: list[[单词],[单词].....]\n",
    "    '''\n",
    "    sents = []\n",
    "    with open(path, \"r\", encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            if line != \"\":\n",
    "                line_shuzu = line.split(\" \")  # 按照空格拆分\n",
    "                sents.append(line_shuzu)\n",
    "    return sents\n",
    "\n",
    "# 若第一次 运行 构建模型\n",
    "# path = \"Data\\embfea1.0205\"\n",
    "# sentences = getSentences(path)\n",
    "# model = Word2Vec(sentences, min_count=5, size=100, workers=2, window=5, iter=10)\n",
    "# model.save(\"Data\\emb_my_100.bin\")  # 保存模型\n",
    "\n",
    "# 后面载入模型\n",
    "model = Word2Vec.load(\"Data\\emb_my_100.bin\")\n",
    "\n",
    "print(\"函数：\",model[\"函数\"])  # 打印函数的词向量\n",
    "print(\"NUM：\",model[\"NUM\"])  # 打印NUM的词向量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=20603, size=100, alpha=0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programming\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('FUN_VALUE_VAR', 0.6813198328018188), ('偶函数', 0.5755622982978821), ('奇函数', 0.558364748954773), ('原函数', 0.5321136713027954), ('LOG', 0.49604547023773193), ('FUN_VALUE', 0.4925633370876312), ('区间', 0.4851030111312866), ('导函数', 0.48485732078552246), ('一次函数', 0.4819476008415222), ('减函数', 0.4701527953147888)]\n",
      "[('NUM\\n', 0.7388532161712646), ('PLUS', 0.7082787752151489), ('MINUS', 0.685769259929657), ('VAR_QUA', 0.6710989475250244), ('EQUAL', 0.6578972339630127), ('POW', 0.6520572304725647), ('VARx', 0.6335667371749878), ('FRAC', 0.6303172707557678), ('VARa', 0.6237950325012207), ('INEQUAL', 0.6174031496047974)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programming\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "\n",
    "print (model.most_similar('函数'))\n",
    "print(model.most_similar('NUM'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programming\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Programming\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换完毕，样本个数： 700\n",
      "转换完毕，样本个数： 164\n",
      "转换完毕，样本个数： 165\n",
      "[  47.33381026   -9.67503911   -8.22311176   83.79172309    7.33977439\n",
      "   41.09439278  -91.23730839 -117.01973066  -75.72460647   24.62504798\n",
      "   -1.83490632  -38.57968573    1.31144634  -20.47615191   25.09380344\n",
      "  -80.8660152   109.35541284   18.09958444   11.51868912   53.17818687\n",
      "    6.40405091   43.67676827  -64.11598376   29.95224351 -153.94778579\n",
      "   37.9948571    -8.74233765  -70.38884231    1.40611013  104.94119688\n",
      "  -28.70774866  -86.56133669   20.73661254   55.59556261   14.07421954\n",
      "   67.65926692  -62.55489458  -33.15947646    1.93600065  -55.95975275\n",
      "  -80.78175315  -62.75935346   -0.79109673   49.29034337   16.34252421\n",
      "   20.75557961   54.58805919   64.27934194    0.68587422  -99.07220448\n",
      "    5.79061812  -31.32292832  -10.30711842   51.40635674   90.60440365\n",
      "  -13.49232894   17.71760238  -11.80977659  -45.67592717  -16.10368052\n",
      "    1.63594147   25.40058633   34.05247611  -56.34272638  -27.43536234\n",
      "  -53.43331459   -5.1100856   -66.61655437  -29.28656124  -47.14599837\n",
      "    2.55245423   29.65680038  -13.3623901     9.1017415     5.70563131\n",
      "  -33.9416714   -31.61242838   51.4842623    -9.12478602  -56.85287528\n",
      "  113.44199662    1.06437974  124.32761467  -43.66896392   27.73211293\n",
      "  -84.88972542  -66.98150025    8.37506269  -83.55139968   61.52096952\n",
      "   -1.10976733   33.56553666  -13.99262489   16.4736437   -10.37175128\n",
      "  131.98728124  -51.61966636   32.08649538   48.29288208   14.29749616]\n",
      "[ -5.62387147   7.36829824  -6.84233787 -53.40307171  15.69720278\n",
      " -29.13801495  -2.13444921 -17.92861097  -7.25078536  30.35028955\n",
      " -10.73946496  -4.01224337  -5.92271917 -12.64295093   9.48617852\n",
      " -37.79260214 -26.53168316  -7.51533184 -15.97679094  41.65045113\n",
      " -33.43222085  -2.11565664 -53.02514074 -29.70562201 -30.79240939\n",
      " -28.35001364  42.00449663   2.67886326 -11.77346164  14.14947937\n",
      " -30.6913738    4.57476295 -18.75920681   3.80257047 -14.53451928\n",
      "  16.38696911 -22.8958655  -40.24200508  29.92753969   1.72002901\n",
      " -16.55259764  10.95462115 -19.16710982 -22.07662589  11.42840743\n",
      "   5.92425846  36.44423651  25.21246371  21.89683536 -54.27935263\n",
      "  -2.02314185 -30.74702312   3.50960972 -12.92754271   7.87494099\n",
      " -32.82096873  10.49594596  45.49472557 -33.13555741  -2.39350324\n",
      " -23.30752979  15.96923546  13.45729005  26.78157082   2.89518033\n",
      "  37.85103937  -0.62215131  38.13390942  -6.30142566   2.76524593\n",
      " -20.40833424  10.02724133 -22.41961225  17.02226691  15.10469324\n",
      "   4.031121   -17.20301378  63.29997167  -0.31781346   2.73201841\n",
      " -26.03132006 -11.3998735   13.9375008  -12.74201027  11.61357757\n",
      " -37.07790162  36.9763841  -18.22542467  -9.72941606  25.70343731\n",
      "  15.95402674 -35.7834136   35.29271894  36.03591799 -47.37196262\n",
      "  34.85992894   0.99203764   3.70421858   8.61520616 -10.33019156]\n",
      "[ -51.35743763   33.51522901   18.09491397   -5.14994124  147.59393618\n",
      "   24.5358664  -123.47809954   38.87516686 -117.66922546   65.89366308\n",
      "   41.55668321   35.33748302   38.48669633   27.46416067  -66.2052146\n",
      "  -11.39663661   60.08491943  -18.97697764   30.50173356  -44.71998587\n",
      "   60.8230274   -19.37169982    4.90939992  -86.6276786    22.70716982\n",
      "   56.72302544  -49.32460866   41.43927966  -54.09398058   27.66143721\n",
      "  -52.11445162  -64.87149314   33.1124114    76.90458724  -21.81394517\n",
      "   74.76685284  -43.67947665    3.24476609   49.00568174    7.7092041\n",
      " -151.44274265  -50.10119567 -109.48588796   36.05964419  -69.16730094\n",
      "  -22.3472721   121.34915763  113.10246094  105.46318647 -255.60852026\n",
      "  -25.96038672  -76.10265837  -95.5208892    -3.22197431  115.5410033\n",
      "  -17.89855143  150.87416635   50.16663809   -7.24602743  -93.94851151\n",
      "  -70.65635304   95.48471274  -15.29697432  -70.76964816 -127.19870891\n",
      "   27.1287042    27.67822752   76.60792855 -201.20307712  -45.26391741\n",
      "   28.32648648 -117.70487804   26.44795351    4.30380604  -35.61361193\n",
      "  -10.01840466   30.60340615   89.67306535  -18.19271154  -80.18231536\n",
      "  112.54627751  -46.99058213   48.46646609   46.01518256   73.27651317\n",
      "   16.72635233 -112.02804089  -57.25338889   44.69044215  -56.36851344\n",
      "  -86.27589875   71.61117566  115.63140134   77.02256926   21.12885264\n",
      "   93.02479278   -8.14842958  -13.80343266  -41.79907559 -103.54569174]\n"
     ]
    }
   ],
   "source": [
    "# 用简单的方法构建句子特征。 词向量相加：\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def transformX2vec(test_xx): # 输入x给出 vec形式的数据\n",
    "    test_xx_vec =[]\n",
    "    for sentence in test_xx:\n",
    "        sentence_vec = np.zeros(100) # 向量维度100\n",
    "        for word in sentence :\n",
    "            if word in model:\n",
    "                word_vec = model[word]\n",
    "                sentence_vec += word_vec\n",
    "        test_xx_vec.append(sentence_vec)\n",
    "    print ('转换完毕，样本个数：',len(test_xx_vec))\n",
    "#     test_xxx_vec = preprocessing.scale(test_xx_vec)# 标准化向量\n",
    "    return test_xx_vec\n",
    "\n",
    "# 把三个样本进行向量化\n",
    "train_x_vct = transformX2vec(train_x)\n",
    "crossVali_x_vct = transformX2vec(crossVali_x)\n",
    "test_x_vct = transformX2vec(test_x)\n",
    "\n",
    "print (train_x_vct[0])\n",
    "print (crossVali_x_vct[0])\n",
    "print (test_x_vct[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.模型训练：多标签模型knn、svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsRestClassifier(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
      "           weights='uniform'),\n",
      "          n_jobs=1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[[0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0]]\n",
      "[[0 0 1 1 0 0]\n",
      " [0 0 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier #（一对多的模型，可以尝试OneVsOne）\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classifi = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=9))\n",
    "\n",
    "# classifi = OneVsRestClassifier(LinearSVC())\n",
    "\n",
    "# classifi = OneVsRestClassifier(DecisionTreeClassifier())\n",
    "\n",
    "\n",
    "print(classifi)\n",
    "# 训练\n",
    "\n",
    "classifi.fit(train_x_vct, train_y_lable) \n",
    "# 预测cv集结果\n",
    "predictions = classifi.predict(crossVali_x_vct)\n",
    "# 观测结果\n",
    "print(type(predictions[0]))\n",
    "print(type(crossVali_y_lable[0]))\n",
    "\n",
    "# predictions.astype(float)\n",
    "\n",
    "print(predictions[0:2])\n",
    "print(crossVali_y_lable[0:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.交叉验证cross validation，选择优参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision Score:  0.8717948717948718\n",
      "Recall Score:  0.3655913978494624\n",
      "f1-score:  0.5151515151515151\n"
     ]
    }
   ],
   "source": [
    "# 衡量模型好坏，然后回去train选择更好的参数\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(crossVali_y_lable , predictions, average='micro')\n",
    "recall = recall_score(crossVali_y_lable, predictions, average='micro')\n",
    "f1 = f1_score(crossVali_y_lable, predictions, average=\"micro\")  # micro weighted macro \n",
    "\n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision Score: \", precision)\n",
    "print(\"Recall Score: \", recall)\n",
    "print(\"f1-score: \", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.用test data 输出不同模型的准确度，给出展示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------分类指标的文本报告--------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.70      0.74        46\n",
      "          1       0.92      0.14      0.25        84\n",
      "          2       0.98      0.41      0.58       156\n",
      "          3       0.85      0.66      0.74        44\n",
      "          4       0.33      0.22      0.27         9\n",
      "          5       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.89      0.40      0.52       345\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programming\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# 先预测\n",
    "predictions111 = classifi.predict(test_x_vct)\n",
    "\n",
    "# 输出结果\n",
    "print()\n",
    "print('-----------------------分类指标的文本报告--------------------------')\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(test_y_lable, predictions111))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
